{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import imageio\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "youtube-dl --rm-cache-dir\n",
    "\n",
    "youtube-dl -f bestvideo https://youtu.be/Fkadv0VnZkI\n",
    "\n",
    "youtube-dl -f bestvideo https://www.youtube.com/playlist?list=PLAPUEAObdbMb747QUFsjQ2e9MPz1FkDnQ\n",
    "\n",
    "youtube-dl -f bestvideo https://www.youtube.com/playlist?list=PLAPUEAObdbMaBtaElCDD3XD4hWO631ihN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ffmpeg -i video1.webm -r 1 second_iteration/%06d_img.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_path = Path('../sport_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_suffixes = [n.suffix for n in videos_path.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts(videos_suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ''\n",
    "for i, p in enumerate(videos_path.iterdir()):\n",
    "    if p.suffix in ['.mp4', '.webm']:\n",
    "        command += f'ffmpeg -i \"{p.name}\" -r 10 second_iteration/vid_{i:02}_%05d.jpg; '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('../sport_data/second_iteration/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = [n.suffix for n in dataset_path.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts(suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in dataset_path.iterdir():\n",
    "    if p.suffix.lower() not in ['.jpg', '.png', '.jpeg']:\n",
    "        p.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    print(i, len(list(dataset_path.glob(f'vid_{i:02}*'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for p in sorted(list(dataset_path.glob('vid_04*')))[540:550]:\n",
    "    images.append(imageio.imread(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(images[-5:])):\n",
    "    plt.figure()\n",
    "    plt.imshow(images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pose detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See instructions in ./deep-high-resolution-net.pytorch/demo/run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = Path('/home/evgenykashin/projects/sport/deep-high-resolution-net.pytorch/demo/output2/boxes/')\n",
    "poses = Path('/home/evgenykashin/projects/sport/deep-high-resolution-net.pytorch/demo/output2/poses/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for b in list(bboxes.iterdir())[:5]:\n",
    "    plt.figure()\n",
    "    plt.imshow(plt.imread(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for b in list(poses.iterdir())[:5]:\n",
    "    plt.figure()\n",
    "    plt.imshow(plt.imread(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose detection coords processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_df = pd.read_csv('/home/evgenykashin/projects/sport/deep-high-resolution-net.pytorch/demo/output2/pose-data.csv',\n",
    "                       encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_df.box_top_left_x = poses_df.box_top_left_x.astype(int)\n",
    "poses_df.box_top_left_y = poses_df.box_top_left_y.astype(int)\n",
    "poses_df.box_bottom_right_x = poses_df.box_bottom_right_x.astype(int)\n",
    "poses_df.box_bottom_right_y = poses_df.box_bottom_right_y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_row(row):\n",
    "    box_left = (row.box_top_left_x, row.box_top_left_y)\n",
    "    box_right = (row.box_bottom_right_x, row.box_bottom_right_y)\n",
    "\n",
    "    foot_left = (row.nose_x, row.nose_y)\n",
    "    knee_left = (row.left_eye_x, row.left_eye_y)\n",
    "    hip_left = (row.right_eye_x, row.right_eye_y)\n",
    "    hip_right = (row.left_ear_x, row.left_ear_y)\n",
    "    knee_right = (row.right_ear_x, row.right_ear_y)\n",
    "    hip_center = (row.right_shoulder_x, row.right_shoulder_y)\n",
    "    top_center = (row.left_elbow_x, row.left_elbow_y)\n",
    "    wrist_left = (row.right_wrist_x, row.right_wrist_y)\n",
    "    shoulder_left = (row.right_hip_x, row.right_hip_y)\n",
    "    shoulder_right = (row.left_knee_x, row.left_knee_y)\n",
    "    wrist_right = (row.left_ankle_x, row.left_ankle_y)\n",
    "    head_top = (row.left_wrist_x, row.left_wrist_y)\n",
    "    head_bottom = (row.right_elbow_x, row.right_elbow_y)\n",
    "    foot_right = (row.left_shoulder_x, row.left_shoulder_y)\n",
    "    \n",
    "    return box_left, box_right, foot_left, knee_left, hip_left, hip_right, \\\n",
    "           knee_right, hip_center, top_center, wrist_left, shoulder_left, \\\n",
    "           shoulder_right, wrist_right, head_top, head_bottom, foot_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_on_image(row, img):\n",
    "    box_left, box_right, foot_left, knee_left, hip_left, hip_right, \\\n",
    "           knee_right, hip_center, top_center, wrist_left, shoulder_left, \\\n",
    "           shoulder_right, wrist_right, head_top, head_bottom, foot_right = extract_from_row(row)\n",
    "\n",
    "    img = cv2.rectangle(img, box_left, box_right, color=(0, 255, 0), thickness=3)\n",
    "\n",
    "    img = cv2.circle(img, foot_left, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'ft_L', foot_left, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, knee_left, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'kn_L', knee_left, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, knee_right, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'kn_R', knee_right, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, hip_left, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'hip_L', hip_left, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, hip_right, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'hip_R', hip_right, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, hip_center, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'hip', hip_center, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, top_center, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'top_C', top_center, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, wrist_left, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'wr_L', wrist_left, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, shoulder_left, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'shdr_L', shoulder_left, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, shoulder_right, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'shdr_R', shoulder_right, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, wrist_right, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'wr_R', wrist_right, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, head_top, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'head_T', head_top, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, head_bottom, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'head_B', head_bottom, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    img = cv2.circle(img, foot_right, 4, (255, 0, 0), 2)\n",
    "    img = cv2.putText(img, 'ft_R', foot_right, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 255, thickness=2)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_image(row, img):\n",
    "    box_left, box_right, foot_left, knee_left, hip_left, hip_right, \\\n",
    "           knee_right, hip_center, top_center, wrist_left, shoulder_left, \\\n",
    "           shoulder_right, wrist_right, head_top, head_bottom, foot_right = extract_from_row(row)\n",
    "    box_right = (box_right[0], (knee_left[1] + knee_right[1]) // 2)\n",
    "    return img[box_left[1]: box_right[1], box_left[0]: box_right[0], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract usefull crops from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_coord_to_crop(coord, box_l, box_r):\n",
    "    x = min(coord[0] - box_l[0], box_r[0])\n",
    "    y = min(coord[1] - box_l[1], box_r[1])\n",
    "    return (x, y)\n",
    "\n",
    "def extract_from_image_with_points(row, img):\n",
    "    box_left, box_right, foot_left, knee_left, hip_left, hip_right, \\\n",
    "           knee_right, hip_center, top_center, wrist_left, shoulder_left, \\\n",
    "           shoulder_right, wrist_right, head_top, head_bottom, foot_right = extract_from_row(row)\n",
    "    box_right = (box_right[0], (knee_left[1] + knee_right[1]) // 2)\n",
    "    \n",
    "    hip_left = map_coord_to_crop(hip_left, box_left, box_right)\n",
    "    hip_right = map_coord_to_crop(hip_right, box_left, box_right)\n",
    "    shoulder_left = map_coord_to_crop(shoulder_left, box_left, box_right)\n",
    "    shoulder_right = map_coord_to_crop(shoulder_right, box_left, box_right)\n",
    "    head_bottom = map_coord_to_crop(head_bottom, box_left, box_right)\n",
    "    \n",
    "    return img[box_left[1]: box_right[1], box_left[0]: box_right[0], :],\\\n",
    "        (hip_left, hip_right, shoulder_left, shoulder_right, head_bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize and pad of crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, keypoints, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        new_w, new_h = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        new_w, new_h = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized_image = cv2.resize(image.copy(), (new_w, new_h), interpolation = inter)\n",
    "    \n",
    "    resized_keypoints = []\n",
    "    for k in keypoints:\n",
    "        resized_keypoints.append((int(k[0] * (new_w / w)), int(k[1] * (new_h / h))))\n",
    "    # return the resized image\n",
    "    return resized_image, resized_keypoints\n",
    "\n",
    "def image_pad(image, keypoints, width=None, height=None):\n",
    "    (h, w, c) = image.shape\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    \n",
    "    if width is None:\n",
    "        raise NotImplementedError()\n",
    "    else:\n",
    "        pad_image = np.zeros((h, width, c), dtype=np.uint8)\n",
    "        pad_keypoints = []\n",
    "        \n",
    "        if w < width:\n",
    "            pad_size = width - w\n",
    "            pad_left = pad_size // 2\n",
    "            pad_right = pad_left + w\n",
    "            pad_image[:, pad_left:pad_right, :] = image.copy()\n",
    "            \n",
    "            for k in keypoints:\n",
    "                pad_keypoints.append((k[0] + pad_left, k[1]))\n",
    "        else:\n",
    "            crop_size = w - width\n",
    "            crop_left = crop_size // 2\n",
    "            crop_right = crop_left + width\n",
    "            pad_image = image[:, crop_left:crop_right, :].copy()\n",
    "            \n",
    "            for k in keypoints:\n",
    "                pad_keypoints.append((k[0] - crop_left, k[1]))\n",
    "    \n",
    "    return pad_image, pad_keypoints\n",
    "\n",
    "def resize_pad(image, keypoints, width=None, height=None):\n",
    "    image = image[:, :, :3]\n",
    "    if image.dtype == np.float32:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        \n",
    "    res_image, res_keyp = image_resize(image, keypoints, height=height)\n",
    "    pad_image, pad_keyp = image_pad(res_image, res_keyp, width=width)\n",
    "    return pad_image, pad_keyp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.codeproject.com/Articles/865830/Point-cloud-alignment-ICP-methods-compared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zpincus/celltool/blob/master/celltool/numerics/image_warp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmarks_match(src_im, src_landmarks, tar_landmarks): \n",
    "    \"\"\"\n",
    "    umeyama(src, dst, estimate_scale), \n",
    "    src/dst landmarks coord. should be (y, x)\n",
    "    \"\"\"\n",
    "    src_size = src_im.shape\n",
    "    src_tmp = [(int(xy[1]), int(xy[0])) for xy in src_landmarks]\n",
    "    dst_tmp = [(int(xy[1]), int(xy[0])) for xy in tar_landmarks]\n",
    "    M1 = umeyama(np.array(src_tmp), np.array(dst_tmp), True)\n",
    "\n",
    "    result1 = cv2.warpAffine(src_im.copy(), M1.astype(np.float32)[:2], (src_size[1], src_size[0]), borderMode=cv2.BORDER_REPLICATE) \n",
    "    return result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from umeyama import umeyama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_images = 0\n",
    "target_width, target_height = 512, 640\n",
    "mean_keypoints = np.loadtxt('mean_keypoints.txt', dtype=np.int32) # from EDA.ipynb\n",
    "\n",
    "for i in tqdm.tqdm(range(len(poses_df))):\n",
    "    fname = poses_df.iloc[i].fname\n",
    "    box_num = poses_df.iloc[i].box_num\n",
    "    name = fname.split('/')[-1]\n",
    "\n",
    "    try:\n",
    "        img = plt.imread('../sport_data/second_iteration/' + name)\n",
    "    except:\n",
    "        print('Error with opening', name)\n",
    "        continue\n",
    "\n",
    "    row = poses_df.iloc[i]\n",
    "    img, keypoints = extract_from_image_with_points(row, img)\n",
    "    \n",
    "    if img.shape[0] < 400:\n",
    "        small_images += 1\n",
    "        continue\n",
    "        \n",
    "    pad_image, pad_keyp = resize_pad(img, keypoints, target_width, target_height)\n",
    "    aligned_img = landmarks_match(pad_image, pad_keyp, mean_keypoints)\n",
    "    \n",
    "    new_name = name.split('.')[0]\n",
    "    if is_debug:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(aligned_img)\n",
    "        break\n",
    "    else:\n",
    "        imageio.imsave(f'aligned_bodies2/{new_name}_{box_num}.jpg', aligned_img)\n",
    "print('small_images', small_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
